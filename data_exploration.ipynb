{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46a1f9-a30c-4583-bacd-ab5c5b3620c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow[and-cuda] scikit-learn matplotlib seaborn pandas imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272254bf-aec7-43da-807e-2467d322244d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Proyecto Aprendizaje Automático: Predicción del Alzheimer\n",
    "\n",
    "Santiago Valdez Bocardo\n",
    "\n",
    "Sebastián Arturo Jácome Herrera\n",
    "\n",
    "Este código realiza un análisis y modelado predictivo del diagnóstico de Alzheimer utilizando Machine Learning y Deep Learning.\n",
    "\n",
    "Pasos principales:\n",
    "1. **Carga y exploración de datos**: Se analiza la estructura del dataset.\n",
    "2. **Preprocesamiento**: Se eliminan columnas redundantes, se codifican variables categóricas y se escalan datos numéricos.\n",
    "3. **Balanceo de clases**: Se aplican técnicas de Near Miss y SMOTE para abordar el desbalance en los datos.\n",
    "4. **Entrenamiento de modelos**: Se prueban modelos de Decision Tree, Logistic Regression, SVM y Neural Network.\n",
    "5. **Reducción de dimensionalidad**: Se aplica PCA para mejorar el desempeño de los modelos.\n",
    "6. **Optimización del mejor modelo**: Se usa GridSearch para ajustar hiperparámetros en la red neuronal.\n",
    "7. **Evaluación y visualización de resultados**: Se calculan métricas como Accuracy, Precision, Recall y F1-Score y se generan visualizaciones de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e0c48-6725-46c3-a689-07d054a38467",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn import tree\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import layers\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d9a5c-6139-4759-a4ae-b2197cf67c95",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c01ac4-aaf5-41af-827f-1bd0b40fd809",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Primeras filas\n",
    "\n",
    "Mostrar las primeras filas del dataset para tener una idea general de su contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc0432-fa66-421d-b878-2e25896b5c19",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"./alzheimers_prediction_dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1608c15f-faaa-4b41-bbdd-ee6ed0ff2600",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23773e4-f6b4-4493-965a-704380d0cdf9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Alzheimer’s Prediction Dataset (Global) es un conjunto de datos que contiene 74,283 registros provenientes de 20 países distintos. Este conjunto de datos es útil para modelos predictivos, estudios epidemiológicos e investigaciones sanitarias sobre la enfermedad de Alzheimer.\n",
    "\n",
    "\n",
    "\n",
    "Atributos del Dataset\n",
    "\n",
    "\n",
    "* Datos Demográficos:\n",
    "\n",
    "Country: País de origen del individuo.\n",
    "\n",
    "Age: Edad del individuo.\n",
    "\n",
    "Gender: Género (Male/Female).\n",
    "\n",
    "Education Level: Nivel educativo alcanzado (expresado en años de educación).\n",
    "\n",
    "* Factores de Estilo de Vida:\n",
    "\n",
    "Physical Activity Level: Nivel de actividad física (Bajo, Medio, Alto).\n",
    "\n",
    "Smoking Status: Estado de tabaquismo (Nunca, Exfumador, Actual).\n",
    "\n",
    "Alcohol Consumption: Frecuencia de consumo de alcohol (Nunca, Ocasionalmente, Regularmente).\n",
    "\n",
    "Dietary Habits: Tipo de alimentación (Saludable, Promedio).\n",
    "\n",
    "Air Pollution Exposure: Nivel de exposición a la contaminación del aire (Bajo, Medio, Alto).\n",
    "\n",
    "Social Engagement Level: Nivel de participación en actividades sociales (Bajo, Medio, Alto).\n",
    "\n",
    "Urban vs Rural Living: Lugar de residencia (Urbano/Rural).\n",
    "\n",
    "* Factores Médicos:\n",
    "\n",
    "BMI: Índice de Masa Corporal (IMC).\n",
    "\n",
    "Diabetes: Presencia de diabetes (Sí/No).\n",
    "\n",
    "Hypertension: Hipertensión arterial (Sí/No).\n",
    "\n",
    "Cholesterol Level: Nivel de colesterol (Normal/Alto).\n",
    "\n",
    "Family History of Alzheimer’s: Antecedentes familiares de Alzheimer (Sí/No).\n",
    "\n",
    "Cognitive Test Score: Puntuación en pruebas cognitivas.\n",
    "\n",
    "Depression Level: Nivel de depresión (Bajo, Medio, Alto).\n",
    "\n",
    "Sleep Quality: Calidad del sueño (Buena, Regular, Pobre).\n",
    "\n",
    "\n",
    "Stress Levels: Niveles de estrés (Bajo, Medio, Alto).\n",
    "\n",
    "* Factores Genéticos y Económicos:\n",
    "\n",
    "Genetic Risk Factor (APOE-ε4 allele): Presencia del alelo APOE-ε4 (Sí/No).\n",
    "\n",
    "Income Level: Nivel de ingresos (Bajo, Medio, Alto).\n",
    "\n",
    "Employment Status: Estado laboral (Empleado, Desempleado, Jubilado).\n",
    "\n",
    "Marital Status: Estado civil (Soltero, Casado, Viudo).\n",
    "\n",
    "* Variable Objetivo:\n",
    "\n",
    "Alzheimer’s Diagnosis: Diagnóstico de Alzheimer, variable binaria con los valores:\n",
    "\n",
    "0 (No): No se ha diagnosticado Alzheimer.\n",
    "\n",
    "1 (Sí): Diagnóstico positivo de Alzheimer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce49c9-8048-4121-a945-20ce7ecde0fc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exploración de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb7bcfd-5a23-4e17-a225-5473e147a3ef",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Información General del Dataset\n",
    "\n",
    "Análisis de la estructura general del dataset, incluyendo el número de columnas y tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d5f86-17aa-407e-85d5-e923b8c33ee9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4c455-88de-478b-87cb-0719c999b57e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d0e92-1ab6-4a88-8c47-3b46d91c0caf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58722724-32fd-4e44-a5f9-b34f65ba9b53",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f047b-63a4-478d-a2b4-940327ca8163",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Datos Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59cb16-cfce-415c-8e2d-c97edced3a07",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "duplicated = df[df.duplicated()]\n",
    "duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5938ee-1b9e-489c-b54a-b6395026a3a2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ee87b-2b06-47e4-a1e8-38c0619f45db",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(df.columns)):\n",
    "    ben = df.groupby(df.columns[i]).count()\n",
    "    print(\"Column: \", ben.iloc[:, 0])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de020e3b-2b81-4d2c-b076-2279fdba0ec9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "There are 2 types of possible results:\n",
    "* Yes with 30713 rows\n",
    "* No with 43570 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75358d8e-4aad-481a-9195-6842d37aaf0f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Estadísticas generales\n",
    "\n",
    "Visualización de estadísticas descriptivas para evaluar la distribución de las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c6e57-6594-4dd4-b60d-59fa91b130e7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be031263-1571-41c8-88d3-bbe642972c54",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c10dd4-2c87-47d8-be3a-e06821ccc332",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Distribución de variable objetivo\n",
    "\n",
    "Esto ayuda a identificar si la variable objetivo está balanceada o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c3eab-0007-4524-844b-76239ae5e13a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd025a2c-599f-4706-be2f-5dfa2ae1ab22",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "– ¿Cuántos datos tienes, cuántas filas, cuántas columnas?\n",
    "\n",
    "Hay 1857075 datos, 74,283 filas y 25 columnas.\n",
    "\n",
    "– ¿Hay datos faltantes?\n",
    "\n",
    "El dataset no muestra datos faltantes\n",
    "\n",
    "– ¿Hay contenido redundante o duplicado?\n",
    "\n",
    "No se encuentran datos repetidos en el dataset, sin embargo algunas posibles columnas redundantes son:\n",
    "\n",
    "* Country: No aporta información para la predicción individual.\n",
    "* Cognitive Test Score: Correlacionada con la variable objetivo.\n",
    "* Employment Status, Marital Status, Income Level, Urban vs Rural Living:\n",
    " Podrían estar cubiertas por otras variables como Social Engagement Level o Education Level.\n",
    "\n",
    "– ¿Cuál es la distribución de los datos en la clase objetivo?\n",
    "\n",
    "Alzheimer’s Diagnosis (Variable Objetivo):\n",
    "* No (sin Alzheimer): 58.65%\n",
    "* Sí (con Alzheimer): 41.35%\n",
    "\n",
    "La distribución no está completamente balanceada, pero no es un caso extremo de desbalanceo, así que se puede dejar como está\n",
    "\n",
    "– ¿Existen correlaciones entre las categorías?\n",
    "\n",
    "De acuerdo con la matriz, no hay correlaciones significativas entre las variables numéricas\n",
    "\n",
    "Age, Education Level, BMI, y Cognitive Test Score tienen valores de correlación cercanos a 0 entre sí, indicando que no hay relaciones lineales fuertes entre estas variables.\n",
    "\n",
    "\n",
    "Dado que no hay una relación fuerte entre las variables numéricas, no parece haber redundancia dentro de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28b13a-d48c-4ec8-b0a1-088e59013f50",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.drop(columns=[\n",
    "    \"Country\",\n",
    "    \"Cognitive Test Score\",\n",
    "    \"Employment Status\",\n",
    "    \"Marital Status\",\n",
    "    \"Income Level\",\n",
    "    \"Urban vs Rural Living\"\n",
    "], inplace=True)\n",
    "\n",
    "\n",
    "df_processed = df\n",
    "\n",
    "label_cols = [\n",
    "    \"Smoking Status\", \"Alcohol Consumption\", \"Dietary Habits\"\n",
    "]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in label_cols:\n",
    "    df_processed[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "one_hot_cols = [\n",
    "    \"Gender\", \"Diabetes\", \"Hypertension\", \"Genetic Risk Factor (APOE-ε4 allele)\", \n",
    "    \"Alzheimer’s Diagnosis\", \"Family History of Alzheimer’s\"\n",
    "]\n",
    "\n",
    "df_processed = pd.get_dummies(df_processed, columns = one_hot_cols, drop_first=True)\n",
    "\n",
    "ordinal_cols = [\n",
    "    \"Physical Activity Level\", \"Cholesterol Level\", \"Depression Level\", \"Sleep Quality\", \n",
    "    \"Air Pollution Exposure\", \"Social Engagement Level\", \"Stress Levels\"\n",
    "]\n",
    "\n",
    "ordinal_mappings = { \n",
    "    \"Physical Activity Level\": [\"Low\", \"Medium\", \"High\"],\n",
    "    \"Cholesterol Level\": [\"Normal\", \"High\"],\n",
    "    \"Depression Level\": [\"Low\", \"Medium\", \"High\",],\n",
    "    \"Sleep Quality\": [\"Poor\", \"Average\", \"Good\"],\n",
    "    \"Air Pollution Exposure\": [\"Low\", \"Medium\", \"High\"],\n",
    "    \"Social Engagement Level\": [\"Low\", \"Medium\", \"High\"],\n",
    "    \"Stress Levels\": [\"Low\", \"Medium\", \"High\"]\n",
    "}\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[ordinal_mappings[col] for col in ordinal_cols])\n",
    "df_processed[ordinal_cols] = ordinal_encoder.fit_transform(df_processed[ordinal_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea692ea0-d33d-4ebf-bda3-4a6d0b1b7e6f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802383d-248b-44cc-9613-915f93190a86",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "target_column = df_processed['Alzheimer’s Diagnosis_Yes']\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=target_column, data=df_processed, palette=\"viridis\")\n",
    "plt.title(\"Distribución de Alzheimer’s Diagnosis\")\n",
    "plt.xlabel(\"Diagnóstico de Alzheimer\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93badc0d-fb53-4f50-bf38-01f105345955",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Matriz de Correlación\n",
    "\n",
    "Se genera la matriz para analizar las correlaciones entre variables numéricas y detectar posibles relaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a41c64-6810-48b4-922c-a756c73773f9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(df_processed.corr(), annot=True, fmt=\".2%\", mask=np.triu(np.ones_like(df_processed.corr())))\n",
    "plt.title(\"Matriz de correlación de variables numéricas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ced0b3-5f30-4c7d-a17f-98d32a11d254",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Separación de datos\n",
    "\n",
    "Se separan los datos en entrenamiento y prueba en una proporción 80%-20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0da0d-9212-4a47-949b-8475a679fa78",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = df_processed.drop(columns=[\"Alzheimer’s Diagnosis_Yes\"])\n",
    "y = df_processed[\"Alzheimer’s Diagnosis_Yes\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb6221-cbd9-4aae-a8eb-2c36c9c0e982",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Escalado de variables numericas\n",
    "\n",
    "Se normalizan variables numéricas usando StandardScaler o MinMaxScaler para mejorar el desempeño de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc3639-a52c-4b0d-ab3b-de4117c33489",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "numerical_columns = [\"Age\", \"Education Level\", \"BMI\"]\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1f165-3267-4e9b-b190-ba6994fb29e0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n--- Información después del preprocesamiento ---\")\n",
    "print(X_train.info())\n",
    "print(\"\\n--- Primeras Filas del Dataset Preprocesado ---\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b7900-2f2c-46bd-939e-21a9fd4696ad",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b126827-a37f-49c4-a576-f41411e6e3f7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Aplicación de técnicas de balanceo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2aeeb4-ca74-46ec-9d40-15731c591009",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Random Over Sampling\n",
    "Duplica algunos ejemplos de nuestra clase minoritaria para estar a la par de la mayoritaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01132647-51fc-4a1d-adee-d1c7088149d6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Random Under Sampling\n",
    "Elimina ejemplos de la clase mayoritaria para estar a la par de la minoritaria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9337bd1-33ad-485b-945d-c1951ba33675",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Near-miss\n",
    "Reduce la cantidad de muestras de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb297d-4ad7-48a9-8572-11f2456bfcf9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# undersampling\n",
    "nearmiss = NearMiss()\n",
    "X_train_nm, y_train_nm = nearmiss.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039d6a1e-9650-4f0e-81d4-c91bd47a8338",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "SMOTE\n",
    "\n",
    "Genera nuevas muestras sintéticas para la clase minoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8e57d-8ee9-49c7-b96a-1d17ea7f6ed0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# oversampling\n",
    "smote = SMOTE()\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db02de8-3dfb-40f2-9635-e313710d420d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Definición y entrenamiento de modelos\n",
    "\n",
    "Se entrena y evalúa cada modelo con los datasets original, Near Miss y SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da53391-00f0-4bac-b064-1944d5cfe817",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeada47c-450f-4a70-b09d-bb56de36ee66",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    for dataset_name, X_tr, y_tr in zip([\"Original\", \"Near Miss\", \"SMOTE\"],\n",
    "                                        [X_train, X_train_nm, X_train_sm],\n",
    "                                        [y_train, y_train_nm, y_train_sm]):\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results.append([model_name, dataset_name, accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c588a-3a78-4793-b06a-fa6a0bbe3f8c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Red neuronal\n",
    "\n",
    "Se implementa una red neuronal con capas densas y dropout para evitar sobreajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1f2b2-1d71-4f68-a8bd-55e44fecc3ed",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_neural_network(X_train, y_train, X_test, y_test, dataset_name):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2, verbose=0)\n",
    "\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    results.append([\"Neural Network\", dataset_name, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4218f-3688-4c53-a895-b9e2c04c581c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_neural_network(X_train, y_train, X_test, y_test, \"Original\")\n",
    "train_neural_network(X_train_nm, y_train_nm, X_test, y_test, \"Near Miss\")\n",
    "train_neural_network(X_train_sm, y_train_sm, X_test, y_test, \"SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caf40b8-e99b-4a9b-b839-a9d1ede137e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"Modelo\", \"Dataset\", \"Accuracy\"])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84109159-1f8d-4c39-b35c-d057382ab53b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43f777-7584-49cc-9767-2cf408fe6767",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Random Under Sampling\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = undersampler.fit_resample(X, y)\n",
    "print(len(X_under), len(y_under))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(class_weight='balanced' , max_iter=1000 , random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "results.append([\"Logistic Regression\", 'Random Under Sampling', model.score(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad3c69-2c72-4a44-a7de-d1abe4355d45",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Random Over Sampling\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_over, y_over = oversampler.fit_resample(X, y)\n",
    "print(len(X_over), len(y_over))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(class_weight='balanced' , max_iter=1000 , random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "results.append([\"Logistic Regression\", 'Random Over Sampling', model.score(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bb134-57cf-4ce9-8988-5231f1928549",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d1663-ccd2-4b1d-a700-f045734f4aac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Random Under Sampling\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = undersampler.fit_resample(X, y)\n",
    "print(len(X_under), len(y_under))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "dt_under = tree.DecisionTreeClassifier()\n",
    "dt_under = dt_under.fit(X_train, y_train)\n",
    "dt_under.score(X_test, y_test)\n",
    "results.append([\"Decision Tree\", 'Random Under Sampling', dt_under.score(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80301452-6581-4ceb-a70b-3d3cfc5d2fc8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Random Over Sampling\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_over, y_over = oversampler.fit_resample(X, y)\n",
    "print(len(X_over), len(y_over))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "dt_over = tree.DecisionTreeClassifier()\n",
    "dt_over = dt_over.fit(X_train, y_train)\n",
    "dt_over.score(X_test, y_test)\n",
    "results.append([\"Decision Tree\", 'Random Over Sampling', dt_over.score(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584cf52-b99d-45a1-845a-5caa7ddb1cbc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a38c6a1-0204-4d33-875c-5ab3af098a9d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Aquí continuación se usa el escalador MinMaxScaler, que en general nos dio mejores resultados. También, por alguna razón, nos dio algunos errores el intentar hacerlo con StandardScaler al principio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87003b8f-c74b-41db-80fb-f0c634869d65",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df_processed)\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=df_processed.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2753218-1806-4e93-8f07-3de881420d95",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Under Sampler\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = undersampler.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "model = keras.Sequential([])\n",
    "model.add(keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=10)\n",
    "res_nn = model.evaluate(X_test, y_test)\n",
    "print(res_nn)\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "results.append([\"Neural Network\", 'Random Under Sampling', train_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9532f9-e25f-40e7-97b1-31404d92e0ec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Over Sampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_over, y_over = oversampler.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "model = keras.Sequential([])\n",
    "model.add(keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=10)\n",
    "res_nn = model.evaluate(X_test, y_test)\n",
    "print(res_nn)\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "results.append([\"Neural Network\", 'Random Over Sampling', train_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8205c32-b9eb-4daf-a7c0-4b5a37b4123b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad745f4-4565-4483-9dd5-7df09d337e71",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Random Under Sampling\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = undersampler.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "svm_under = SVC(kernel='rbf')\n",
    "svm_under.fit(X_train, y_train)\n",
    "svm_under.score(X_test, y_test)\n",
    "results.append([\"SVM\", 'Random Under Sampling', svm_under.score(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a462607f-b1cb-4e00-b034-d0e7048144b0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Random Over Sampling\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_over, y_over = oversampler.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "svm_over = SVC(kernel='rbf')\n",
    "svm_over.fit(X_train, y_train)\n",
    "svm_over.score(X_test, y_test)\n",
    "results.append([\"SVM\", 'Random Over Sampling', svm_over.score(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe53bf-c852-4cc7-af0c-bfed39b64672",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sorted_results = sorted(results, key=lambda x: x[2], reverse=True)\n",
    "results_df = pd.DataFrame(sorted_results, columns=[\"Modelo\", \"Algoritmo\", \"Accuracy\"])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dff81e-bf0b-4713-955c-96f1f37d6e54",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Es importante denotar que puede que, debido a la cercanía entre precisiones, varíen los 3 mejores resultados.\n",
    "En nuestra última ejecución, se pudo observar que los mejores resultados fueron:\n",
    "\n",
    "Neural Network Over Sampling -> 0.7238\n",
    "Neural Network Under Sampling -> 0.7237\n",
    "Decision Tree Over Sampling -> 0.7168\n",
    "\n",
    "Se usarán estos modelos para PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e051e49-06aa-4ee0-9e69-15588a09b2ce",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# PCA\n",
    "Se usa PCA para reducir la dimensionalidad (cantidad de variables) y eliminar ruido en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206acb6e-97f1-4bb5-af60-04a280c26730",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = df_scaled.drop(\"Alzheimer’s Diagnosis_Yes\", axis=1)\n",
    "y = df_scaled['Alzheimer’s Diagnosis_Yes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "reduced_exp_variance = list()\n",
    "\n",
    "total=0\n",
    "for n in range(len(explained_variance)):\n",
    "    total += explained_variance[n]\n",
    "    reduced_exp_variance.append(explained_variance[n])\n",
    "    if(total>0.9):\n",
    "        break\n",
    "print(\"Número de componentes que forman el 90%: \", n)\n",
    "print(reduced_exp_variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f6d5d-bc83-4d28-8a7b-28149b18ec04",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Visualización de la varianza explicada por los componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdede59f-c100-4650-9944-1f69c5c9704d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "background_color = \"#ffffff\"\n",
    "fig = plt.figure(figsize=(20,7), facecolor=background_color)\n",
    "plt.bar(range(n+1), reduced_exp_variance, alpha=0.5, align='center', label='Individual Explained Variance')\n",
    "plt.ylabel('Explained Variance Ratio',  fontsize = 18)\n",
    "plt.xlabel('Principal Components', fontsize = 18)\n",
    "plt.title('Explained Variance Ratio vs Principal Components', fontsize = 25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77201bab-c7d0-4bb6-8d05-7e4a51463056",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Se muestra que el valor se encuentra en los primeros 14 componentes, ya que explican la mayor parte de la varianza; se utilizarán para la aplicación del PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d33736-d64a-4d5b-9ddd-6f187cae5290",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural Network Random Over Sampler (1er Lugar)\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_over, y_over = oversampler.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "pca = PCA(n_components=n)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([])\n",
    "model.add(keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=10)\n",
    "res_nn = model.evaluate(X_test, y_test)\n",
    "print(res_nn)\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374a72f-cbf0-427e-a7c1-ed20d8b6a43d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural Network Random Under Sampler (2do Lugar)\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = undersampler.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "\n",
    "pca = PCA(n_components=n)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "model = keras.Sequential([])\n",
    "model.add(keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=10)\n",
    "res_nn = model.evaluate(X_test, y_test)\n",
    "print(res_nn)\n",
    "train_accuracy = history.history['accuracy'][-1]\n",
    "print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4ccfc-ea87-4247-a0f0-a84c1dbc60df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Decision Tree Random Over Sampling (3er Lugar)\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_over, y_over = oversampler.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "pca = PCA(n_components=n)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "dt_over = tree.DecisionTreeClassifier()\n",
    "dt_over = dt_over.fit(X_train, y_train)\n",
    "dt_over.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4cfdf-dda5-4af8-8cf6-49078bafe7dd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0d0d2-20ea-4859-a8eb-d91de0669037",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "En nuestro caso, incluso después de realizar el PCA. Se obtuvieron mejores resultados con el Neural Network utilizando Random Over Sampling.\n",
    "Por lo que se hará el GridSearch con este modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb4e9d-bd6e-470a-980b-35ceff8e90cc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Se decidió hacer Grid Search manualmente debido a  errores encontrados al intentar usar GridSearchCV con KerasClassifier.\n",
    "GridSearchCV no funcionaba correctamente con KerasClassifier, generando el error '__sklearn_tags__ not found'. Esto nos forzó a realizarlo de forma manual, que es más tardado pero dará resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499dbe6-f3d9-48f6-b169-3a35fb840053",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural Network Random Over Sampler (GridSearchCV)\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_over, y_over = oversampler.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "def create_model(neurons1, neurons2, neurons3, optimizer):\n",
    "    model = keras.Sequential([])\n",
    "    model.add(keras.Input(shape=(X_train.shape[1],)))\n",
    "    model.add(keras.layers.Dense(neurons1, activation='relu'))\n",
    "    model.add(keras.layers.Dense(neurons2, activation='relu'))\n",
    "    model.add(keras.layers.Dense(neurons3, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "parameters = {\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'neurons1': [64, 32],\n",
    "    'neurons2': [32, 16],\n",
    "    'neurons3': [16, 8],\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [5, 10],\n",
    "}\n",
    "\n",
    "param_combinations = list(itertools.product(\n",
    "    parameters['optimizer'],\n",
    "    parameters['neurons1'],\n",
    "    parameters['neurons2'],\n",
    "    parameters['neurons3'],\n",
    "    parameters['batch_size'],\n",
    "    parameters['epochs']\n",
    "))\n",
    "    \n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for optimizer, neurons1, neurons2, neurons3, batch_size, epochs in param_combinations:\n",
    "    print(f\"Entrenando con: optimizer={optimizer}, neurons layer 1={neurons1}, neurons layer 2={neurons2}, neurons layer 3={neurons3}, batch_size={batch_size}, epochs={epochs}\")\n",
    "\n",
    "    model = create_model(neurons1, neurons2, neurons3, optimizer)\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0, validation_split=0.2)\n",
    "\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = (optimizer, neurons1, neurons2, neurons3, batch_size, epochs)\n",
    "        best_y_pred = y_pred\n",
    "\n",
    "print(\"\\nMejores hiperparámetros encontrados:\")\n",
    "print(f\"Optimizer: {best_params[0]}, Neurons layer 1: {best_params[1]}, Neurons layer 2={best_params[2]}, Neurons layer 3={best_params[3]}, Batch Size: {best_params[4]}, Epochs: {best_params[5]}\")\n",
    "print(f\"Mejor Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51143f3-e5b5-4cee-bf35-f7cc8d620f9e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Mejor modelo del GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3943720f-96f3-4e8f-9060-05b1ebe5ba72",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "A continuación se grafica visualmente la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e211f-b5e4-4192-bf82-93939e54ff33",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, best_y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix Heatmap (SVM - Random Over Sampling)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6d22a-5ece-401a-8876-a7e664d31f0b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55923fa9-15a5-4d2b-8b8a-9bd6be4c4e86",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Para no afectar valores que ya fueron ejecutados, para este paso se decidió entrenar los modelos nuevamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94cd58-e041-4d78-b7a0-da6a06e46506",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Neural Network Random Under Sampler (2do Lugar antes de GridSearch)\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_under, y_under = undersampler.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "model = keras.Sequential([])\n",
    "model.add(keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=10)\n",
    "res_nn = model.evaluate(X_test, y_test)\n",
    "print(res_nn)\n",
    "train_accuracy = history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d09dc-e154-4b5c-954c-2787f7d834b7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Resultados Del GridSearch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a0d53-0410-4d06-b3f9-b50af51613c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "A continuación, se mostrará una gráfica que compara el modelo SVM, tanto con GridSearch, como sin este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be575a-cc60-4a51-bfbe-c50296f4ec1e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "results = [\n",
    "    [\"Neural Network Random Over Sampling con GridSearch\", best_accuracy],\n",
    "    [\"Neural Network Random Under Sampling Sin GridSearch\", train_accuracy]\n",
    "]\n",
    "df_results = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\"])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.barplot(data=df_results, x=\"Model\", y=\"Accuracy\", palette=\"Blues\")\n",
    "plt.xlabel(\"Model Type\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Comparison: GridSearch Best vs SVM RBF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de71c2b2-7ffc-4eb1-bf40-084dc455988f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Análisis de evaluación "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e107fcf1-0ca1-4d43-8369-6459d5de272b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "1. Comparación entre métricas de modelos\n",
    "\n",
    "La evaluación de los modelos se realizó con las métricas: Accuracy, Precision, Recall y F1-Score.\n",
    "\n",
    "* Accuracy: El modelo con mejor accuracy es Neural Network con SMOTE (0.7228), seguido de SVM con datos originales (0.7195) y Logistic Regression con SMOTE (0.7144). Esto es sin contar las ejecuciones de los modelos anteriores, donde, en general, el modelo con mejor accuracy es Neural Network con SMOTE (0.7256)\n",
    "* Precision: La precisión más alta es obtenida por Logistic Regression con SMOTE (0.6356) y Neural Network con datos originales (0.6593), y esto indica que cuando predicen la presencia de Alzheimer, son modelos confiables.\n",
    "* Recall: El mejor recall lo obtuvo SVM con Near Miss (0.7610) y SVM con SMOTE (0.7501). Debido a esto se concluye que estos modelos identificaron mejor los casos positivos.\n",
    "* F1-Score: La métrica que balancea precisión y recall tiene sus mejores valores en Neural Network con SMOTE (0.6721) y SVM con SMOTE (0.6818).\n",
    "\n",
    "\n",
    "Con este análisis, podemos concluir que Neural Network con SMOTE es el mejor modelo, ya que logra el mejor balance entre todas las métricas, mostrando que no solamente se predice correctamente, sino que mantiene un buen recall y precisión a su vez.\n",
    "\n",
    "2. Impacto del Balanceo de Clases\n",
    "Se analizaron los efectos de las técnicas de balanceo Near Miss y SMOTE y se concluyó lo siguiente:\n",
    "\n",
    "* SMOTE mejoró la mayoría de los modelos, logrando mejores valores en accuracy y recall al generar datos sintéticos en la clase minoritaria, sobre todo con Neural Network, como ya vimos.\n",
    "* Near Miss redujo el rendimiento en general, ya que al eliminar datos puede haber perdido información relevante.\n",
    "\n",
    "\n",
    "3. Interpretación de la matriz de confusión\n",
    "La Matriz de Confusión del mejor modelo (Neural Network con SMOTE) mostró:\n",
    "\n",
    "Altos valores en la diagonal principal, lo que indica que predice correctamente la mayoría de los casos. Hubieron errores pero no considerables para tomar el modelo como malo.\n",
    "\n",
    "Hubieron menos falsos negativos comparado con otros modelos, lo cual es importante en caso de problemas médicos, ya que identificar correctamente casos positivos es lo más importante.\n",
    "\n",
    "Con esto se puede concluir que Neural Network con SMOTE no solo obtuvo el mejor accuracy, sino que su matriz de confusión confirma que es el más confiable en la detección de Alzheimer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd08e2-71a6-4a76-8ddc-eee2503df385",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Interpretación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105796bd-91f1-4f5b-a564-c6d58993c34d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Evaluación del impacto del balanceo de clases \n",
    "\n",
    "Los datos antes del balanceo de clases mostraron una pequeña desproporción con la variable objetivo, haciendo que pudiera afectar el rendimiento de los modelos. Debido a esto, se aplicaron técnicas de **Near Miss** (undersampling) y **SMOTE** (oversampling) para equilibrar las clases.\n",
    "Los resultados obtenidos mostraron que:\n",
    "- **SMOTE** mejoró el rendimiento en la mayoría de los modelos, especialmente en Neural Network y Logistic Regression.\n",
    "- **Near Miss** generalmente disminuyó la precisión debido a la eliminación de datos relevantes, por lo que no funcionó mucho para este proyecto\n",
    "- **SVM** y **Neural Network** se beneficiaron más del balanceo, obteniendo su mayor accuracy con SMOTE. Estos modelos se utilizaron para seguir con la evaluación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2157c67-792e-4cb6-bce9-5c9f0768fec3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Importancia de las características y PCA\n",
    "\n",
    "Se aplicó PCA para reducir la dimensionalidad y mejorar el desempeño de los modelos. PCA logra esto eliminando ruido y redundancias en las variables, lo que es útil para este proyecto.\n",
    "Los obtenidos mostraron que:\n",
    "- **Neural Network con SMOTE y PCA obtuvo un accuracy de 71.76%**, manteniendo un buen desempeño con menos características. Este fue, por mucho, el mejor accuracy de todos nuestros modelos\n",
    "- **SVM y Logistic Regression mostraron una ligera disminución en accuracy tras haber aplicado PCA**, esto muestra que esta reducción de características no fue beneficiosa para estos modelos.\n",
    "- En general, PCA nos permitió mejorar la eficiencia sin sacrificar demasiado el rendimiento, aunque no para todos los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ebe3b-1e32-43a8-bf65-7adf47c22f0c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Conclusiones y visualización de resultados\n",
    "\n",
    "Con este proyecto se pudo demostrar la importancia de realizar un pipeline completo de Machine Learning para el entrenamiento de modelos paraciertos proyectos, en este caso para un proyecto sobre Alzheimer. Se realizaron múltiples experimentos con técnicas de balanceo de clases, selección de características y optimización de hiperparámetros, para de esta forma poder construir el mejor modelo posible y obtener los mejores resultados.\n",
    "\n",
    "1. **Neural Network con SMOTE y Grid Search es el mejor modelo**, alcanzando una accuracy superior a los otros métodos.\n",
    "2. **SMOTE es la mejor estrategia de balanceo**, ya que permitió mejorar la precisión sin perder información relevante.\n",
    "3. **PCA ayudó a reducir la complejidad del modelo**, aunque su impacto en la precisión varió según el algoritmo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab110a5-3aba-4977-bc01-9865007a8b8e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc1117-0011-4183-b85d-7dcf08028b78",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/Users/sjacome/.venvs/ml_3.11/bin/python3",
    "-Xfrozen_modules=off",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "ml311",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "ml311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "name": "data_exploration.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
